# EMBEDR v2.0

Author: Eric Johnson \
Date Created: July 1, 2021 \
Email: eric.johnson643@gmail.com

## Overview

**E**mpirical **M**arginal resampling **B**etter **E**valuates
**D**imensionality **R**eduction, or **EMBEDR**, is a method for evaluating the
extent to which an embedding generated by a dimensionality reduction algorithm
contains structures that are more similar to the structures in the
high-dimensional space than we expect by random chance.  The method applies the
concept of an empirical hypothesis test, where a null distribution for a sample
statistic is generated via marginal resampling, in order to estimate whether
samples are better-embedded than a given DRA might do by chance.

For complete details, see our
[preprint](https://www.biorxiv.org/content/10.1101/2020.11.18.389031v2). 

## New in Version 2.0

The updated version of the EMBEDR package better facilitates the EMBEDR 
algorithm as described in 
[our manuscript](https://www.biorxiv.org/content/10.1101/2020.11.18.389031v2) 
by improving the flow of data between stages of the algorithm. In particular, 
we greatly reduce the number of times that kNN graphs and affinity matrices 
are calculated; attemping to re-use calculations as often as possible.

This version of the algorithm also supports the sample-wise specification of
the `perplexity` and `n_neighbors` parameters, which are common hyperparameters
for dimensionality reduction algorithms.

## To-Do

- Add plotting scripts
    - Single embedding with EMBEDR p-Values
- Finish `EMBEDR_sweep` class


